{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gerumo.data.dataset import describe_dataset\n",
    "from gerumo.data.generators import build_generator\n",
    "from gerumo.utils.engine import (\n",
    "    setup_cfg, setup_environment, setup_experiment, setup_model,\n",
    "    build_dataset, build_callbacks, build_metrics, build_optimizer, build_loss\n",
    ")\n",
    "from gerumo.models.base import build_model\n",
    "from gerumo.visualization.metrics import training_history\n",
    "\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "args = dotdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['config_file'] = '/home/ir-riqu1/gerumo2/config/rf_classification_debug.yml'\n",
    "#args['config_file'] = '/home/ir-riqu1/gerumo2/config/cnn_classification.yml'\n",
    "args['opts'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = setup_cfg(args)\n",
    "output_dir = setup_experiment(cfg)\n",
    "logger = setup_environment(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(cfg, 'train')\n",
    "describe_dataset(train_dataset, logger,\n",
    "                save_to=output_dir / \"train_description.txt\")\n",
    "validation_dataset = build_dataset(cfg, 'validation')\n",
    "describe_dataset(validation_dataset, logger,\n",
    "                save_to=output_dir / \"validation_description.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = build_generator(cfg, train_dataset)\n",
    "validation_generator = build_generator(cfg, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_generator))\n",
    "print(len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100 # integer\n",
    "criterion = 'gini' # 'gini' or 'entropy'\n",
    "max_depth = None # null or integer\n",
    "min_samples_split = 2 # integer or float\n",
    "min_samples_leaf = 1 # integer or float\n",
    "min_weight_fraction_leaf = 0.0 # float\n",
    "max_features = 3 # 'auto', 'sqrt', 'log2', integer or float\n",
    "max_leaf_nodes = None # null or integer\n",
    "min_impurity_decrease = 0.0 # float\n",
    "bootstrap = False # True or False\n",
    "oob_score= False # True or False\n",
    "n_jobs = -1 # null or integer\n",
    "random_state = 42 # null or integer or RandomState\n",
    "verbose = 0 # integer\n",
    "warm_start = False # 'True' or 'False'\n",
    "class_weight = None # 'balanced', 'balanced_subsample', null, dict or list of dicts\n",
    "ccp_alpha = 0.0 # non-negative float\n",
    "max_samples = None # null, integer or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "criterion = 'gini'\n",
    "min_samples_split = 2\n",
    "min_samples_leaf = 1\n",
    "min_weight_fraction_leaf = 0.0\n",
    "max_features = 3\n",
    "min_impurity_decrease = 0.0\n",
    "random_state = 42\n",
    "bootstrap = True\n",
    "max_samples = 0.7\n",
    "verbose = 0\n",
    "n_jobs = -1\n",
    "warm_start = True\n",
    "oob_score = True\n",
    "max_samples = None # null, integer or float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape = train_generator.get_input_shape()\n",
    "#model = build_model(cfg, input_shape)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators = n_estimators,\n",
    "    criterion = criterion,\n",
    "    max_depth = max_depth,\n",
    "    min_samples_split = min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "    max_features = max_features,\n",
    "    min_impurity_decrease = min_impurity_decrease,\n",
    "    random_state = random_state,\n",
    "    bootstrap = bootstrap,\n",
    "    verbose = verbose,\n",
    "    n_jobs = n_jobs,\n",
    "    warm_start = warm_start,\n",
    "    oob_score = oob_score,\n",
    "    ccp_alpha = ccp_alpha,\n",
    "    max_samples = max_samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build training tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks = build_callbacks(cfg)\n",
    "#metrics = build_metrics(cfg)\n",
    "#optimizer = build_optimizer(cfg)\n",
    "#loss = build_loss(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = setup_model(\n",
    "#    model, train_generator, optimizer, loss, metrics\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.fit_mode()\n",
    "validation_generator.fit_mode()\n",
    "score=[]\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "start_time = time.time()\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(train_generator, total=len(train_generator)) \n",
    "for i, (batch_inputs, batch_outputs) in enumerate(pbar):\n",
    "    labels=enc.fit_transform(batch_outputs).toarray()\n",
    "    #batch_inputs_norm=sc.fit_transform(batch_inputs)\n",
    "    rf.fit(batch_inputs, labels)\n",
    "    rf.n_estimators+=1\n",
    "    score.append(rf.oob_score_)\n",
    "    \n",
    "    \n",
    "    \n",
    "training_time = (time.time() - start_time)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Training time: {training_time:.3f} [min]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(train_generator, total=len(train_generator))\n",
    "predictions_tr=[]\n",
    "true_tr=[]\n",
    "\n",
    "for i, (batch_inputs, batch_outputs) in enumerate(pbar):\n",
    "    labels_tr=enc.fit_transform(batch_outputs).toarray()\n",
    "    #batch_inputs_norm=sc.fit_transform(batch_inputs)\n",
    "    predictions_tr.extend(rf.predict(batch_inputs))\n",
    "    true_tr.extend(labels_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(validation_generator, total=len(validation_generator))\n",
    "predictions=[]\n",
    "true=[]\n",
    "true_batches=[]\n",
    "start_time = time.time()\n",
    "for i, (batch_inputs, batch_outputs) in enumerate(pbar):\n",
    "    true_batches.extend(batch_outputs)\n",
    "    labels=enc.fit_transform(batch_outputs).toarray()\n",
    "    #batch_inputs_norm=sc.fit_transform(batch_inputs)\n",
    "    pre = rf.predict(batch_inputs)\n",
    "    predictions.extend(pre)\n",
    "    #print(accuracy_score(labels,np.array(pre)))\n",
    "    true.extend(labels)\n",
    "    \n",
    "training_time = (time.time() - start_time)/60.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Testing time: {training_time:.3f} [min]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(np.array(true),np.array(predictions))\n",
    "acc_tr=accuracy_score(np.array(true_tr),np.array(predictions_tr))\n",
    "print('trained on: {}'.format(cfg.DATASETS.TRAIN.EVENTS[58:]))\n",
    "print('tested on: {}'.format(cfg.DATASETS.VALIDATION.EVENTS[58:]))\n",
    "print('{0} Testing Accuracy : {1:.4f}'.format(cfg.MODEL.TELESCOPES[0],acc))\n",
    "print('{0} Training Accuracy : {1:.4f}'.format(cfg.MODEL.TELESCOPES[0],acc_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(predictions).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(true).sum(axis=0).max()/np.array(true).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest 2nd Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100 # integer\n",
    "criterion = 'gini' # 'gini' or 'entropy'\n",
    "max_depth = None # null or integer\n",
    "min_samples_split = 2 # integer or float\n",
    "min_samples_leaf = 1 # integer or float\n",
    "min_weight_fraction_leaf = 0.0 # float\n",
    "max_features = 3 # 'auto', 'sqrt', 'log2', integer or float\n",
    "max_leaf_nodes = None # null or integer\n",
    "min_impurity_decrease = 0.0 # float\n",
    "bootstrap = True # True or False\n",
    "oob_score= True # True or False\n",
    "n_jobs = -1 # null or integer\n",
    "random_state = 42 # null or integer or RandomState\n",
    "verbose = 1 # integer\n",
    "warm_start = True # 'True' or 'False'\n",
    "class_weight = None # 'balanced', 'balanced_subsample', null, dict or list of dicts\n",
    "ccp_alpha = 0.0 # non-negative float\n",
    "max_samples = None # null, integer or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(\n",
    "    n_estimators = n_estimators,\n",
    "    criterion = criterion,\n",
    "    max_depth = max_depth,\n",
    "    min_samples_split = min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "    max_features = max_features,\n",
    "    min_impurity_decrease = min_impurity_decrease,\n",
    "    random_state = random_state,\n",
    "    bootstrap = bootstrap,\n",
    "    verbose = verbose,\n",
    "    n_jobs = n_jobs,\n",
    "    warm_start = warm_start,\n",
    "    oob_score = oob_score,\n",
    "    ccp_alpha = ccp_alpha,\n",
    "    max_samples = max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = build_generator(cfg, train_dataset)\n",
    "validation_generator = build_generator(cfg, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.fit_mode()\n",
    "validation_generator.fit_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "output=[]\n",
    "for batch_inputs, batch_outputs in train_generator:\n",
    "    features.extend(batch_inputs)\n",
    "    labels=enc.fit_transform(batch_outputs).toarray()\n",
    "    output.extend(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features=[]\n",
    "test_output=[]\n",
    "for batch_inputs, batch_outputs in validation_generator:\n",
    "    test_features.extend(batch_inputs)\n",
    "    test_labels=enc.fit_transform(batch_outputs).toarray()\n",
    "    test_output.extend(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2.fit(np.array(features),np.array(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=rf2.predict(np.array(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(np.array(test_output),np.array(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_output).sum(axis=0).max()/np.array(test_output).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "m = CategoricalAccuracy()\n",
    "m.update_state(np.array(pred), np.array(test_output))\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23622b7acbfecceb6c580e6612f57b6025739422d4e7cd9ec8a6770dedfbf18a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
